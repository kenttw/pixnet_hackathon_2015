{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/big/opt/spark-1.3.1/python/lib/py4j-0.8.2.1-src.zip', '/big/opt/spark-1.3.1/python', '', '/big/home/kent/git/pixnet_hackathon_2015', '/usr/lib/python2.7', '/usr/lib/python2.7/plat-linux2', '/usr/lib/python2.7/lib-tk', '/usr/lib/python2.7/lib-old', '/usr/lib/python2.7/lib-dynload', '/usr/local/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages/PIL', '/usr/lib/python2.7/dist-packages/gtk-2.0', '/usr/lib/pymodules/python2.7', '/usr/local/lib/python2.7/dist-packages/IPython/extensions']\n",
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 1.3.1\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.3 (default, Mar 13 2014 11:03:55)\n",
      "SparkContext available as sc, HiveContext available as sqlContext.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.8.2.1-src.zip'))\n",
    "\n",
    "print sys.path\n",
    "\n",
    "execfile(os.path.join(spark_home, 'python/pyspark/shell.py'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.feature import Word2Vec\n",
    "inp = sc.textFile('./data/new_parsed_no_spam.txt').map(lambda row: row.split(\" \"))\n",
    "word2vec = Word2Vec()\n",
    "model = word2vec.fit(inp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(user_tags,open(\"./data/user_tags.pkl\",'w'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tag mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import jieba ,util\n",
    "import csv ,json\n",
    "jieba.load_userdict(\"./new.dict_all\")\n",
    "stop_words = util.load_stop_words('stopword.txt')\n",
    "from pyspark.mllib.feature import Vectors\n",
    "stop_words = util.load_stop_words('stopword.txt')\n",
    "\n",
    "\n",
    "for line in open(\"./data/cookies_tags.csv.1\"):#buf :\n",
    "    cookie ,tags = line.split(',')\n",
    "    b = Vectors.dense(np.zeros(100))\n",
    "    count = 0\n",
    "    for tag in tags.split(':') :\n",
    "        if len(tag) > 4 :\n",
    "            tags = jieba.cut(tag,cut_all = False)\n",
    "            for item in tags :\n",
    "                if item in stop_words: continue\n",
    "                try:\n",
    "                    b = b + model.transform(item)\n",
    "                    count = count + 1\n",
    "                except ValueError :\n",
    "                    pass\n",
    "        else :\n",
    "            try:\n",
    "                b = b + model.transform(tag)\n",
    "                count = count + 1\n",
    "\n",
    "            except ValueError :\n",
    "                pass\n",
    "    if count == 0 :\n",
    "        user_tags[cookie] = b\n",
    "    else :\n",
    "        user_tags[cookie] = b/count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('./data/cookies_tags.csv.1.vec', 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=' ',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for cookie in user_tags :\n",
    "        vec = user_tags[cookie]\n",
    "        writer.writerow(vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Within Set Sum of Squared Error = 53627.2265609\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.clustering import KMeans, KMeansModel\n",
    "from numpy import array\n",
    "from math import sqrt\n",
    "\n",
    "# Load and parse the data\n",
    "data = sc.textFile(\"./data/cookies_tags.csv.1.vec\")\n",
    "parsedData = data.map(lambda line: array([float(x) for x in line.split(' ')]))\n",
    "\n",
    "# Build the model (cluster the data)\n",
    "clusters = KMeans.train(parsedData, 10, maxIterations=1000,\n",
    "        runs=100, initializationMode=\"random\")\n",
    "\n",
    "# Evaluate clustering by computing Within Set Sum of Squared Errors\n",
    "def error(point):\n",
    "    center = clusters.centers[clusters.predict(point)]\n",
    "    return sqrt(sum([x**2 for x in (point - center)]))\n",
    "\n",
    "WSSSE = parsedData.map(lambda point: error(point)).reduce(lambda x, y: x + y)\n",
    "print(\"Within Set Sum of Squared Error = \" + str(WSSSE))\n",
    "\n",
    "# Save and load model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster: 0\n",
      "雪肌精: 0.787666022778\n",
      "超效: 0.771770954132\n",
      "柳晶凍: 0.767135679722\n",
      "攜帶型: 0.766468405724\n",
      "240ml: 0.766070902348\n",
      "十勝特: 0.765772402287\n",
      "濃膠: 0.762619614601\n",
      "Kanebo: 0.76225143671\n",
      "潔顏粉: 0.761189639568\n",
      "15ML: 0.75984197855\n",
      "cluster: 1\n",
      "晶鑽桂馥: 0.846288323402\n",
      "防曬隔離霜: 0.841037452221\n",
      "超效: 0.840361237526\n",
      "SPF10: 0.836658537388\n",
      "隔離霜: 0.832134544849\n",
      "OREAL: 0.831935405731\n",
      "SPF20: 0.829072237015\n",
      "Sofina: 0.828664958477\n",
      "密粉: 0.826496899128\n",
      "ORBIS: 0.826453268528\n",
      "cluster: 2\n",
      "日本藥妝: 0.875204265118\n",
      "日本: 0.71024286747\n",
      "大阪必買: 0.705878674984\n",
      "藥妝店: 0.697661161423\n",
      "電器行: 0.687138974667\n",
      "motherways: 0.683901846409\n",
      "好買: 0.683260202408\n",
      "餐廚: 0.681079089642\n",
      "必買: 0.66852504015\n",
      "藥妝: 0.666158497334\n",
      "cluster: 3\n",
      "負離子吹風機: 0.859180152416\n",
      "雪肌精: 0.855478584766\n",
      "禮就: 0.821446239948\n",
      "貴桑桑: 0.821358859539\n",
      "快煮壺: 0.820593595505\n",
      "千片: 0.816514968872\n",
      "噴噴: 0.814507484436\n",
      "Anya: 0.812125682831\n",
      "Revive: 0.811225473881\n",
      "采雪泡: 0.811107933521\n",
      "cluster: 4\n",
      "面霜: 0.831860780716\n",
      "極潤: 0.829899013042\n",
      "PH5: 0.829073607922\n",
      "乳是: 0.82768446207\n",
      "保濕: 0.825880289078\n",
      "雪晶靈: 0.820730447769\n",
      "FeeLife: 0.820348620415\n",
      "水乳: 0.818243563175\n",
      "安絲: 0.817625403404\n",
      "活氧特潤: 0.815166950226\n",
      "cluster: 5\n",
      "減重: 0.729329884052\n",
      "多喝水: 0.674757361412\n",
      "孕期: 0.66714411974\n",
      "節食: 0.652758598328\n",
      "母乳: 0.646436452866\n",
      "肥胖: 0.634298563004\n",
      "奶量: 0.630047619343\n",
      "滋補: 0.623379230499\n",
      "害喜: 0.623227536678\n",
      "調養: 0.619971513748\n",
      "cluster: 6\n",
      "蜂毒: 0.778626024723\n",
      "攜帶型: 0.765002191067\n",
      "Kanebo: 0.757535994053\n",
      "240ml: 0.757527530193\n",
      "十勝特: 0.756873607635\n",
      "柳晶凍: 0.755248248577\n",
      "濃膠: 0.75186342001\n",
      "這罐: 0.751422226429\n",
      "超效: 0.751118600368\n",
      "潔顏粉: 0.750367939472\n",
      "cluster: 7\n",
      "這罐: 0.766361474991\n",
      "保養品: 0.758870959282\n",
      "柳晶凍: 0.754413187504\n",
      "雪肌精: 0.753473579884\n",
      "面膜: 0.752787768841\n",
      "十勝特: 0.750624477863\n",
      "肌研: 0.747960925102\n",
      "BOBBI: 0.747652113438\n",
      "攜帶型: 0.742332994938\n",
      "施巴: 0.740555465221\n",
      "cluster: 8\n",
      "SPF10: 0.866022646427\n",
      "蘭吉兒: 0.837427735329\n",
      "防曬隔離霜: 0.836463272572\n",
      "蛋肌: 0.834587812424\n",
      "又潤: 0.834479570389\n",
      "SPF35: 0.833531320095\n",
      "banila: 0.832057952881\n",
      "13g: 0.830287396908\n",
      "一式: 0.826098024845\n",
      "ORBIS: 0.821631968021\n",
      "cluster: 9\n",
      "Kanebo: 0.758593261242\n",
      "攜帶型: 0.75580227375\n",
      "蜂毒: 0.748610794544\n",
      "眼藥水: 0.746614634991\n",
      "潔顏粉: 0.742809653282\n",
      "240ml: 0.742449998856\n",
      "品是: 0.739953637123\n",
      "紫草: 0.738954007626\n",
      "日本必買: 0.737601041794\n",
      "聖品: 0.735155880451\n"
     ]
    }
   ],
   "source": [
    "c1 = clusters.clusterCenters[0]\n",
    "count = 0 \n",
    "\n",
    "for c1 in clusters.clusterCenters :\n",
    "    print \"cluster: \" + str(count)\n",
    "    count = count + 1\n",
    "    synonyms = model.findSynonyms(c1, 10)\n",
    "    for word, cosine_distance in synonyms:\n",
    "        print(\"{}: {}\".format(word.encode('utf-8'), cosine_distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('./data/cookies_tags.csv.1.cluster', 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=' ',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for cookie in user_tags :\n",
    "        vec = user_tags[cookie]\n",
    "        label = clusters.predict(vec)\n",
    "        l = list(vec)\n",
    "        l.insert(0,label)\n",
    "        l.insert(0,cookie)\n",
    "        writer.writerow(l)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
